  0%|                                                                                       | 0/918 [00:00<?, ?it/s]/root/anaconda3/envs/Mixture-of-Debater/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/root/anaconda3/envs/Mixture-of-Debater/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/root/anaconda3/envs/Mixture-of-Debater/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1947: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|â–Ž                                                                            | 4/918 [00:32<1:58:56,  7.81s/it]
{'loss': 1.9295, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.0}
{'loss': 1.9406, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.0}
{'loss': 2.0562, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.0}
{'loss': 1.9181, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.0}
